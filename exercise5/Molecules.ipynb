{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecules\n",
    "\n",
    "- Course: Pattern Recognition\n",
    "- Exercise: Exercise 5 - Molecules\n",
    "- Groupe: chaussette\n",
    "- Students: Sergiy Goloviatinski, Ludovic Heberlin, Hina Khadija, RaphaÃ«l Margueron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "Install the following libaries and their dependencies (pip a requirements file is available):\n",
    "- networkx (for graph manipulation)\n",
    "- numpy, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx==2.4 in /usr/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (2.4)\n",
      "Requirement already satisfied: numpy==1.18.1 in /usr/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.18.1)\n",
      "Requirement already satisfied: scikit_learn==0.22.2.post1 in /usr/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (1.4.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3.8/site-packages (from networkx==2.4->-r requirements.txt (line 5)) (4.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/lib/python3.8/site-packages (from scikit_learn==0.22.2.post1->-r requirements.txt (line 13)) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "GXL_FOLDER = \"./MoleculesClassification/gxl/\"\n",
    "TRAIN_FILE = \"./MoleculesClassification/train.txt\"\n",
    "VALIDATION_FILE = \"./MoleculesClassification/valid.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of graphs for training : 250\n",
      "Nb of graphs for validation : 250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "type_table = {\n",
    "    \"string\": str,\n",
    "    \"int\": int,\n",
    "    \"float\": float\n",
    "}\n",
    "\n",
    "def load_gxl_file(file_name):\n",
    "    full_path = GXL_FOLDER + file_name + \".gxl\"\n",
    "    tree = ET.parse(full_path)\n",
    "    root = tree.getroot()\n",
    "    graph = root.find(\"graph\")\n",
    "    nodes = graph.findall(\"node\")\n",
    "    edges = graph.findall(\"edge\")\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for node in nodes:\n",
    "        node_id = node.get(\"id\")\n",
    "        attr_dict = {attr.get(\"name\"): type_table[attr[0].tag](attr[0].text) for attr in node.findall(\"attr\")}\n",
    "        G.add_node(node_id, attr_dict=attr_dict)\n",
    "\n",
    "    for edge in edges:\n",
    "        edge_from = edge.get(\"from\")\n",
    "        edge_to = edge.get(\"to\")\n",
    "        attr_dict = {attr.get(\"name\"): type_table[attr[0].tag](attr[0].text) for attr in node.findall(\"attr\")}\n",
    "        G.add_edge(edge_from, edge_to, attr_dict=attr_dict)\n",
    "\n",
    "    return G\n",
    "\n",
    "def get_gxl_data(dataset):\n",
    "    lines = [l.split(\" \") for l in open(dataset).read().split(\"\\n\")]\n",
    "    lines = [l for l in lines if len(l) == 2]\n",
    "    \n",
    "    file_names, classes = zip(*lines)\n",
    "    graphs = tuple(load_gxl_file(file_name) for file_name in file_names)\n",
    "\n",
    "    return graphs, classes\n",
    "    \n",
    "    \n",
    "train_graphs, train_classes = get_gxl_data(TRAIN_FILE)\n",
    "validation_graphs, validation_classes = get_gxl_data(VALIDATION_FILE)\n",
    "\n",
    "print(f\"Nb of graphs for training : {len(train_graphs)}\")\n",
    "print(f\"Nb of graphs for validation : {len(validation_graphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ged(G_1, G_2, matrix_form=False, n_approxims=1):\n",
    "    \n",
    "    if(matrix_form):\n",
    "        G_1 = nx.from_scipy_sparse_matrix(G_1)\n",
    "        G_2 = nx.from_scipy_sparse_matrix(G_2)\n",
    "        \n",
    "    ged_generator = nx.optimize_graph_edit_distance(G_1, G_2)\n",
    "    for i in range(n_approxims):\n",
    "        val = next(ged_generator)\n",
    "        \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(dataset):\n",
    "    distance_matrix=[[0 for _ in range(len(dataset))] for _ in range(len(dataset))]\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        for j in range(len(dataset)):\n",
    "            if i>j:\n",
    "                distance_matrix[i][j]=ged(dataset[i],dataset[j])\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        for j in range(len(dataset)):\n",
    "            if i<j:\n",
    "                distance_matrix[i][j]=distance_matrix[j][i]\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8647007943b4904bc9bb8ce6f1f0c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbea45317969434f8d0c2e7d6a0d53b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train=get_distance_matrix(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train = train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='precomputed',\n",
       "                     metric_params=None, n_jobs=4, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {\n",
    "    'n_neighbors':3,\n",
    "    'algorithm':'ball_tree',\n",
    "}\n",
    "\n",
    "metric_params = {\n",
    "    'matrix_form':True,\n",
    "    'n_approxims':1,\n",
    "}\n",
    "\n",
    "nbrs = KNeighborsClassifier(n_neighbors=params['n_neighbors'], \n",
    "                        metric='precomputed',\n",
    "                        n_jobs=4)\n",
    "\n",
    "nbrs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261a57fc28184e8ab0995bc3aaaf4d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10926e1eecfa49298cd3b4bc82721874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_validation=get_distance_matrix(validation_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation=validation_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=nbrs.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_validation, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
