{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# SVM\n",
    "\n",
    "#Loading csv data to numpy arrays\n",
    "def loadData(file, label=True):\n",
    "    csv = open(file,\"r\")\n",
    "    array = []\n",
    "    for line in csv:\n",
    "        array.append(line.strip().split(\",\"))\n",
    "    array = np.asarray(array, dtype=np.int)\n",
    "    if(label):\n",
    "        samples =   array[:,1:]\n",
    "        labels = array[:,0]\n",
    "        return labels, samples\n",
    "    else:\n",
    "        samples = array[:,:]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Training Set\n",
    "def loadTrainSet():\n",
    "    return loadData(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Test Set\n",
    "def loadTestSet():\n",
    "    # return loadData(\"Validation/mnist_test.csv\")\n",
    "    return loadData(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadValidationTestSet():\n",
    "    return loadData(\"Validation/mnist_test.csv\", False)\n",
    "#Application\n",
    "cross_validation = False # True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application started. Loading data...\n",
      "Training set loaded with data size:  60000\n",
      "Test set loaded with data size:  10000\n",
      "Data loaded in  9991  ms. \n"
     ]
    }
   ],
   "source": [
    "print (\"Application started. Loading data...\")\n",
    "start = int(round(time.time() * 1000))\n",
    "y_train, X_train = loadTrainSet()\n",
    "print (\"Training set loaded with data size: \", len(X_train))\n",
    "if(not cross_validation):\n",
    "    # y_test, X_test = loadTestSet()\n",
    "    X_test = loadValidationTestSet()\n",
    "    print (\"Test set loaded with data size: \", len(X_test))\n",
    "print (\"Data loaded in \",int(round(time.time() * 1000)) - start,\" ms. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model generation.\n",
      "Model generated. Time taken for calculations:  369201  ms\n",
      "Application finished in :  437030  ms\n"
     ]
    }
   ],
   "source": [
    "print (\"Starting with model generation.\")\n",
    "calcStart = int(round(time.time() * 1000))\n",
    "#clf = svm.SVC(kernel='linear', C = 0.0001)\n",
    "clf = svm.SVC(kernel='poly', gamma=1.0, C = 1.0, degree=2)\n",
    "#clf = svm.SVC(kernel='rbf', gamma=0.001, C = 1.0)\n",
    "#clf = svm.SVC(kernel='sigmoid', gamma=0.0000001, C = 1.0)\n",
    "predictions = []\n",
    "if(not cross_validation):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print (\"Model generated. Time taken for calculations: \",int(round(time.time() * 1000)) - calcStart, \" ms\")\n",
    "    #print(\"Accuracy: \", clf.score(X_test,y_test))\n",
    "else:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "    print(\"Average Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print (\"Application finished in : \",int(round(time.time() * 1000)) - start, \" ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 994, 1: 1141, 2: 1031, 3: 1009, 4: 983, 5: 890, 6: 952, 7: 1023, 8: 973, 9: 1004}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_file_name = \"predictions.txt\"\n",
    "validation_file = open(\"Validation/\" + validation_file_name, \"w\")\n",
    "for pred_id, prediction in enumerate(predictions):\n",
    "    validation_file.write(str(pred_id) + \", \" + str(prediction) + \"\\n\")\n",
    "    # print(str(pred_id) + \", \" + str(prediction))\n",
    "validation_file.close()\n",
    "\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "summary = dict(zip(unique, counts))\n",
    "print(summary);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
